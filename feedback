Our primary feedback is that while the underlying AI capabilities are exceptionally powerful, the developer experience has a steep learning curve due to inconsistent and unforgiving syntax across the different AI functions. For example, AI.GENERATE_TABLE's rigid requirement for the prompt to be a table subquery (SELECT ...) and for options to be wrapped in a STRUCT is unintuitive compared to the more straightforward string inputs of other functions. A key feature request would be to unify the function signatures, allowing simpler, direct string literals for single-shot generation tasks across all AI functions and supporting top-level named arguments for options instead of requiring a STRUCT. This would dramatically lower the barrier to entry and reduce common syntax errors.
Furthermore, the output from the models requires significant and fragile boilerplate code to be useful. The default response from ML.GENERATE_TEXT is a complex JSON object that must be manually parsed, a process that breaks if the API schema ever changes. We strongly recommend a feature that simplifies this "last mile" of data handling, such as a new function like ML.GENERATE_TEXT_SIMPLE(...) or an optional parameter (extract_text=TRUE) that returns only the clean, generated string content. This would make the most common use case far more robust and would align the product with the goal of rapid, easy development.
In summary, Clinical Guardian proves that BigQuery AI is a game-changing platform capable of solving critical, real-world problems. The product feels like a world-class engine that currently requires expert-level mechanics to operate. By focusing on the developer experience—creating a more consistent, intuitive syntax and simplifying output handling—Google can transform this powerful tool into a truly democratized platform. This would empower more developers to build innovative solutions like ours, not in days of debugging, but in hours of creation.